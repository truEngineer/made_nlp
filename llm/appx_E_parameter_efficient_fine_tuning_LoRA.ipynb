{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff",
      "metadata": {
        "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff"
      },
      "source": [
        "# Appendix E: Parameter-efficient Finetuning with LoRA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUlatTRLcbTU",
        "outputId": "881b29a2-59f8-4aae-d8f0-0ad3c4f13394"
      },
      "id": "oUlatTRLcbTU",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
        "outputId": "cd1241ed-ca01-47f7-b757-e6a48a9c9f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.10.0\n",
            "numpy version: 2.0.2\n",
            "tiktoken version: 0.9.0\n",
            "torch version: 2.6.0+cu124\n",
            "tensorflow version: 2.18.0\n",
            "pandas version: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "        \"tensorflow\", # For OpenAI's pretrained weights\n",
        "        \"pandas\"      # Dataset loading\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21532056-0ef4-4c98-82c7-e91f61c6485e",
      "metadata": {
        "id": "21532056-0ef4-4c98-82c7-e91f61c6485e"
      },
      "source": [
        "## E.1 Introduction to LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66edc999-3d91-4a1c-a157-9d056392e8d8",
      "metadata": {
        "id": "66edc999-3d91-4a1c-a157-9d056392e8d8"
      },
      "source": [
        "- No code in this section\n",
        "- Low-rank adaptation (LoRA) is a machine learning technique that modifies a pretrained model to better suit a specific, often smaller, dataset by adjusting only a small, low-rank subset of the model's parameters\n",
        "- This approach is important because it allows for efficient finetuning of large models on task-specific data, significantly reducing the computational cost and time required for finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1",
      "metadata": {
        "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1"
      },
      "source": [
        "- Suppose we have a large weight matrix $W$ for a given layer\n",
        "- During backpropagation, we learn a $\\Delta W$ matrix, which contains information on how much we want to update the original weights to minimize the loss function during training\n",
        "- In regular training and finetuning, the weight update is defined as follows:\n",
        "\n",
        "$$W_{\\text{updated}} = W + \\Delta W$$\n",
        "\n",
        "- The LoRA method proposed by [Hu et al.](https://arxiv.org/abs/2106.09685) offers a more efficient alternative to computing the weight updates $\\Delta W$ by learning an approximation of it, $\\Delta W \\approx AB$.\n",
        "- In other words, in LoRA, we have the following, where $A$ and $B$ are two small weight matrices:\n",
        "\n",
        "$$W_{\\text{updated}} = W + AB$$\n",
        "\n",
        "- The figure below illustrates these formulas for full finetuning and LoRA side by side"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b",
      "metadata": {
        "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-1.webp\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc",
      "metadata": {
        "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc"
      },
      "source": [
        "- If you paid close attention, the full finetuning and LoRA depictions in the figure above look slightly different from the formulas I have shown earlier\n",
        "- That's due to the distributive law of matrix multiplication: we don't have to add the weights with the updated weights but can keep them separate\n",
        "- For instance, if $x$ is the input data, then we can write the following for regular finetuning:\n",
        "\n",
        "$$x (W+\\Delta W) = x W + x \\Delta W$$\n",
        "\n",
        "- Similarly, we can write the following for LoRA:\n",
        "\n",
        "$$x (W+A B) = x W + x A B$$\n",
        "\n",
        "- The fact that we can keep the LoRA weight matrices separate makes LoRA especially attractive\n",
        "- In practice, this means that we don't have to modify the weights of the pretrained model at all, as we can apply the LoRA matrices on the fly\n",
        "- After setting up the dataset and loading the model, we will implement LoRA in the code to make these concepts less abstract"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
      "metadata": {
        "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
      },
      "source": [
        "## E.2 Preparing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "669c64df-4431-4d27-834d-2bb38a01fc02",
      "metadata": {
        "id": "669c64df-4431-4d27-834d-2bb38a01fc02"
      },
      "source": [
        "- This section repeats the code from chapter 6 to load and prepare the dataset\n",
        "- Instead of repeating this code, one could open and run the chapter 6 notebook and then insert the LoRA code from section E.4 there\n",
        "- (The LoRA code was originally the last section of chapter 6 but was moved to the appendix due to the length of chapter 6)\n",
        "- In a similar fashion, we could also apply LoRA to the models in chapter 7 for instruction finetuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Chapter 6 code\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "\n",
        "def create_balanced_dataset(df):\n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "    # Randomly sample \"ham' instances to match the number of 'spam' instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "    return balanced_df\n",
        "\n",
        "\n",
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "    return train_df, validation_df, test_df"
      ],
      "metadata": {
        "id": "jp7nmkxODAZZ"
      },
      "id": "jp7nmkxODAZZ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
        "outputId": "bd046183-e89a-4e43-c990-27be51b6e405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ],
      "source": [
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "try:\n",
        "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
        "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
        "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
        "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length\n",
        "        # Note: A more pythonic version to implement this method\n",
        "        # is the following, which is also used in the next chapter:\n",
        "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
      ],
      "metadata": {
        "id": "FFR2LC2tDc7b"
      },
      "id": "FFR2LC2tDc7b",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
      "metadata": {
        "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
        "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
        "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
      "metadata": {
        "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
      "metadata": {
        "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
      },
      "source": [
        "- As a verification step, we iterate through the data loaders and check that the batches contain 8 training examples each, where each training example consists of 120 tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
        "outputId": "c8704e6b-1ff2-4ae2-f892-56370b05e4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
      "metadata": {
        "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
      },
      "source": [
        "- Lastly, let's print the total number of batches in each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "IZfw-TYD2zTj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZfw-TYD2zTj",
        "outputId": "6b1c0d7a-313d-461c-f659-a02208111d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604",
      "metadata": {
        "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604"
      },
      "source": [
        "## E.3 Initializing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1",
      "metadata": {
        "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1"
      },
      "source": [
        "- This section repeats the code from chapter 6 to load and prepare the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
        "outputId": "17d9945f-2eb6-47aa-fad3-47c96536f28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 119kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.71MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 134kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:44<00:00, 11.1MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 6.54MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.38MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.61MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from GPTModel import GPTModel\n",
        "from load_weights import load_weights_into_gpt\n",
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(**BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252614cd-7ce6-4908-83e6-3761f519904e",
      "metadata": {
        "id": "252614cd-7ce6-4908-83e6-3761f519904e"
      },
      "source": [
        "- To ensure that the model was loaded corrected, let's double-check that it generates coherent text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
        "outputId": "154462bd-35f6-4ad8-e667-29cc3e297b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ],
      "source": [
        "from generate import generate_text_simple, text_to_token_ids, token_ids_to_text\n",
        "\n",
        "\n",
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8174b31b-1ab5-4115-b01c-245369da5af3",
      "metadata": {
        "id": "8174b31b-1ab5-4115-b01c-245369da5af3"
      },
      "source": [
        "- Then, we prepare the model for classification finetuning similar to chapter 6, where we replace the output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e255ce91-d73a-4854-90a4-95804928eb16",
      "metadata": {
        "id": "e255ce91-d73a-4854-90a4-95804928eb16"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "02e6f057-1383-4ece-8444-0a88e71ac75d",
      "metadata": {
        "id": "02e6f057-1383-4ece-8444-0a88e71ac75d"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is approximately 1.2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# However, the resulting loss values may be slightly different.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#\n",
        "# print(f\"Using {device} device.\")\n",
        "\n",
        "model.to(device);  # no assignment model = model.to(device) necessary for nn.Module classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe",
      "metadata": {
        "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe"
      },
      "source": [
        "- Lastly, let's calculate the initial classification accuracy of the non-finetuned model (we expect this to be around 50%, which means that the model is not able to distinguish between spam and non-spam messages yet reliably)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()  # Disable gradient tracking for efficiency\n",
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "            logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples"
      ],
      "metadata": {
        "id": "ft9PwEZVG8jR"
      },
      "id": "ft9PwEZVG8jR",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
        "outputId": "b2601e13-5f47-498e-c54f-5e965ebe78c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 45.00%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b",
      "metadata": {
        "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b"
      },
      "source": [
        "## E.4 Parameter-efficient finetuning with LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652a4a82-61ef-4d0a-9858-8988e844f12c",
      "metadata": {
        "id": "652a4a82-61ef-4d0a-9858-8988e844f12c"
      },
      "source": [
        "- We begin by initializing a LoRALayer that creates the matrices $A$ and $B$, along with the `alpha` scaling hyperparameter and the `rank` ($r$) hyperparameters\n",
        "- This layer can accept an input and compute the corresponding output, as illustrated in the figure below\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-2.webp\" width=\"200px\">\n",
        "\n",
        "In code, this LoRA layer depicted in the figure above looks like as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2ds9ywjMwvIW",
      "metadata": {
        "id": "2ds9ywjMwvIW"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "class LoRALayer(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
        "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  # similar to standard weight initialization\n",
        "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.alpha * (x @ self.A @ self.B)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad21faa8-0614-4257-93cd-68952193e14a",
      "metadata": {
        "id": "ad21faa8-0614-4257-93cd-68952193e14a"
      },
      "source": [
        "- In the code above, `rank` is a hyperparameter that controls the inner dimension of the matrices $A$ and $B$\n",
        "- In other words, this parameter controls the number of additional parameters introduced by LoRA and is a key factor in determining the balance between model adaptability and parameter efficiency\n",
        "- The second hyperparameter, `alpha`, is a scaling hyperparameter applied to the output of the low-rank adaptation\n",
        "- It essentially controls the extent to which the adapted layer's output is allowed to influence the original output of the layer being adapted\n",
        "- This can be seen as a way to regulate the impact of the low-rank adaptation on the layer's output\n",
        "- So far, the `LoRALayer` class we implemented above allows us to transform the layer inputs $x$\n",
        "- However, in LoRA, we are usually interested in replacing existing `Linear` layers so that the weight update is applied to the existing pretrained weights, as shown in the figure below\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-3.webp\" width=\"200px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f",
      "metadata": {
        "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f"
      },
      "source": [
        "- To incorporate the original `Linear` layer weights as shown in the figure above, we implement a `LinearWithLoRA` layer below that uses the previously implemented LoRALayer and can be used to replace existing `Linear` layers in a neural network, for example, the self-attention module or feed forward modules in an LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "127d3a64-8359-4b21-b056-78d58cc75fe8",
      "metadata": {
        "id": "127d3a64-8359-4b21-b056-78d58cc75fe8"
      },
      "outputs": [],
      "source": [
        "class LinearWithLoRA(torch.nn.Module):\n",
        "    def __init__(self, linear, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.linear = linear\n",
        "        self.lora = LoRALayer(\n",
        "            linear.in_features, linear.out_features, rank, alpha\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x) + self.lora(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1145a90-35ff-462c-820b-15483fa5b051",
      "metadata": {
        "id": "e1145a90-35ff-462c-820b-15483fa5b051"
      },
      "source": [
        "- Note that since we initialize the weight matrix $B$ (`self.B` in `LoRALayer`) with zero values in the LoRA layer, the matrix multiplication between $A$ and $B$ results in a matrix consisting of 0's and doesn't affect the original weights (since adding 0 to the original weights does not modify them)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d",
      "metadata": {
        "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d"
      },
      "source": [
        "- To try LoRA on the GPT model we defined earlier, we define a `replace_linear_with_lora` function to replace all `Linear` layers in the model with the new `LinearWithLoRA` layers\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-4.webp\" width=\"400px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "WlQZ8ygqzN_g",
      "metadata": {
        "id": "WlQZ8ygqzN_g"
      },
      "outputs": [],
      "source": [
        "def replace_linear_with_lora(model, rank, alpha):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            # Replace the Linear layer with LinearWithLoRA\n",
        "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
        "        else:\n",
        "            # Recursively apply the same function to child modules\n",
        "            replace_linear_with_lora(module, rank, alpha)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2",
      "metadata": {
        "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2"
      },
      "source": [
        "- We then freeze the original model parameter and use the `replace_linear_with_lora` to replace the said `Linear` layers using the code below\n",
        "- This will replace the `Linear` layers in the LLM with `LinearWithLoRA` layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
        "outputId": "b595fbf2-8334-4153-cd96-7b9489ed3209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable parameters before: 124,441,346\n",
            "Total trainable parameters after: 0\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters before: {total_params:,}\")\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters after: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "mLk_fPq0yz_u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLk_fPq0yz_u",
        "outputId": "d630299f-b17c-4828-c038-1131baa39424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable LoRA parameters: 2,666,528\n"
          ]
        }
      ],
      "source": [
        "replace_linear_with_lora(model, rank=16, alpha=16)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9",
      "metadata": {
        "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9"
      },
      "source": [
        "- As we can see, we reduced the number of trainable parameters by almost 50x when using LoRA\n",
        "- Let's now double-check whether the layers have been modified as intended by printing the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
        "outputId": "fc40712d-5268-425f-e73c-df9d29b3873e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): MultiHeadAttention(\n",
            "            (W_query): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_key): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (W_value): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (out_proj): LinearWithLoRA(\n",
            "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (lora): LoRALayer()\n",
            "            )\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): LayerNorm()\n",
            "          (1): FeedForward(\n",
            "            (layers): Sequential(\n",
            "              (0): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "              (1): GELU()\n",
            "              (2): LinearWithLoRA(\n",
            "                (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (lora): LoRALayer()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): LinearWithLoRA(\n",
            "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
            "    (lora): LoRALayer()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55",
      "metadata": {
        "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55"
      },
      "source": [
        "- Based on the model architecture above, we can see that the model now contains our new `LinearWithLoRA` layers\n",
        "- Also, since we initialized matrix $B$ with 0's, we expect the initial model performance to be unchanged compared to before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "DAlrb_I00VEU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAlrb_I00VEU",
        "outputId": "e553093d-c155-4df4-df51-e3cac3290466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 45.00%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101",
      "metadata": {
        "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101"
      },
      "source": [
        "- Let's now get to the interesting part and finetune the model by reusing the training function from chapter 6\n",
        "- The training takes about 15 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "# Overall the same as `train_model_simple` in chapter 5\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()  # Calculate loss gradients\n",
        "            optimizer.step()  # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0]  # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ],
      "metadata": {
        "id": "sPmmZt09IRg1"
      },
      "id": "sPmmZt09IRg1",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "wCParRvr0eff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCParRvr0eff",
        "outputId": "675b679c-6426-4251-e5d1-48f57ace90f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 3.820, Val loss 3.462\n",
            "Ep 1 (Step 000050): Train loss 0.396, Val loss 0.364\n",
            "Ep 1 (Step 000100): Train loss 0.111, Val loss 0.229\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Ep 2 (Step 000150): Train loss 0.135, Val loss 0.073\n",
            "Ep 2 (Step 000200): Train loss 0.012, Val loss 0.043\n",
            "Ep 2 (Step 000250): Train loss 0.027, Val loss 0.174\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Ep 3 (Step 000300): Train loss 0.129, Val loss 0.087\n",
            "Ep 3 (Step 000350): Train loss 0.396, Val loss 0.518\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Ep 4 (Step 000400): Train loss 0.006, Val loss 0.118\n",
            "Ep 4 (Step 000450): Train loss 0.013, Val loss 0.111\n",
            "Ep 4 (Step 000500): Train loss 0.052, Val loss 0.158\n",
            "Training accuracy: 100.00% | Validation accuracy: 90.00%\n",
            "Ep 5 (Step 000550): Train loss 0.003, Val loss 0.601\n",
            "Ep 5 (Step 000600): Train loss 0.000, Val loss 0.154\n",
            "Training accuracy: 100.00% | Validation accuracy: 90.00%\n",
            "Training completed in 2.11 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c",
      "metadata": {
        "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c"
      },
      "source": [
        "- Finally, let's evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vdPTJjtKJqsg"
      },
      "id": "vdPTJjtKJqsg",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bawWGijA0iF3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "bawWGijA0iF3",
        "outputId": "82f61a27-5247-419c-d99f-a9b217eddee7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa074723-e3f7-4f7e-a267-855531a037dc",
      "metadata": {
        "id": "aa074723-e3f7-4f7e-a267-855531a037dc"
      },
      "source": [
        "- Note that we previously calculated the accuracy values on 5 batches only via the `eval_iter=5` setting; below, we calculate the accuracies on the full dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "1D2awlEq0gZi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D2awlEq0gZi",
        "outputId": "56d295ca-f285-487a-fc78-f7a5cbc98bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 99.23%\n",
            "Validation accuracy: 94.63%\n",
            "Test accuracy: 95.67%\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d",
      "metadata": {
        "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d"
      },
      "source": [
        "- As we can see based on the relatively high accuracy values above, the LoRA finetuning was successful"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqY3T2y8KEWo",
        "outputId": "c1c8fa3f-7595-494e-b478-15c71481ca6e"
      },
      "id": "uqY3T2y8KEWo",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 27 19:50:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0             33W /   70W |    2034MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}