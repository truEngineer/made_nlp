{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIUDllJT4Vf-"
      },
      "source": [
        "## 7.2 Preparing a dataset for supervised instruction fine-tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgIrPnLh4VgC",
        "outputId": "e0dac7c9-fc71-4cfe-ec36-028e4586d4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:  # 1\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "    with open(file_path, \"r\") as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Gm8KPZ4VgG",
        "outputId": "2a1cd744-dad5-4ef4-d13b-22e14bb300c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Evaluate the following phrase by transforming it into the '\n",
            "                'spelling given.',\n",
            " 'input': 'freind --> friend',\n",
            " 'output': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
            "           'correct spelling is \"friend\".'}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "\n",
        "pprint.pp(data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDsvA8E74VgI"
      },
      "source": [
        "Instruction fine-tuning involves training a model on datasets like the one above.\n",
        "\n",
        "The way we do so is by training them on the text, structuring it into certain formats (called prompt styles).\n",
        "\n",
        "## Apply Alpaca prompt style template\n",
        "```\n",
        "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Evaluate the following phrase by transforming it into the spelling given.\n",
        "\n",
        "### Input:\n",
        "freind --> friend\n",
        "\n",
        "### Output:\n",
        "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n",
        "```\n",
        "\n",
        "## Apply Phi-3 prompt style template\n",
        "```\n",
        "<|user|>\n",
        "Evaluate the following phrase by transforming it into the spelling given: \"freind --> friend\"\n",
        "\n",
        "<|assistant|>\n",
        "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FDYTNek64VgI"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        \"Below is an instruction that describes a task. \"\n",
        "        \"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    # In case there is no input, e.g. for instructions like \"What is an antonym of 'complicated'?\"\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhTRhqM14VgJ",
        "outputId": "e8ebbd54-711f-44ea-c838-1f5d478adc8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Evaluate the following phrase by transforming it into the spelling given.\n",
            "\n",
            "### Input:\n",
            "freind --> friend\n",
            "\n",
            "### Response:\n",
            "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[0])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[0]['output']}\"\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MyG7Ntt4VgK",
        "outputId": "1584e768-8f22-4ebc-edeb-484c7c291bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ],
      "source": [
        "train_portion = int(len(data) * 0.85)\n",
        "test_portion = int(len(data) * 0.1)\n",
        "val_portion = len(data) - train_portion - test_portion\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "\n",
        "print(f\"Training set length: {len(train_data)}\")\n",
        "print(f\"Validation set length: {len(val_data)}\")\n",
        "print(f\"Test set length: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abulmSRh4VgO"
      },
      "source": [
        "## 7.3 Organizing data into training batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0oar1v5n4VgP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plut_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plut_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3BfukiiI4VgQ"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        new_item += [pad_token_id]\n",
        "\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q7XeqyGE4VgT"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        new_item += [pad_token_id]\n",
        "\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        targets = torch.tensor(padded[1:])\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92CKZD8a4VgT",
        "outputId": "8d8a62c9-3e81-413a-e194-3b1ca67b076c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[    1,     2,     3,     4,     5],\n",
              "         [    1,     2,     3, 50256, 50256]]),\n",
              " tensor([[    2,     3,     4,     5, 50256],\n",
              "         [    2,     3, 50256,  -100,  -100]]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for i, item in enumerate(batch):\n",
        "        new_item = item.copy()\n",
        "        new_item += [pad_token_id]\n",
        "\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        targets = torch.tensor(padded[1:])\n",
        "\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor\n",
        "\n",
        "custom_collate_fn([[1,2,3,4,5], [1,2,3]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnBxPbId4VgU"
      },
      "source": [
        "## 7.4 Creating data loaders for an instruction dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KzGvNtfD4VgU"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024  # max context length supported by GPT-2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT4kgpEq5L-u",
        "outputId": "6479015a-0da1-4a80-a5ad-99560b679e8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "quDMNKfA4VgV"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-njxJJx-4VgV"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "   test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_XE2PlF4VgV"
      },
      "source": [
        "## 7.5 Loading a pretrained LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myq8YouM4VgV",
        "outputId": "9f681d1b-544d-4971-ec9f-d6d60027e473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 113kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.80MiB/s]\n",
            "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 138kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [02:29<00:00, 9.48MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 13.1MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 927k/927k [00:00<00:00, 2.28MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.49MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from GPTModel import GPTModel\n",
        "from load_weights import load_weights_into_gpt\n",
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(\n",
        "    context_length=BASE_CONFIG[\"context_length\"],\n",
        "    drop_rate=BASE_CONFIG[\"drop_rate\"],\n",
        "    emb_dim=BASE_CONFIG[\"emb_dim\"],\n",
        "    n_heads=BASE_CONFIG[\"n_heads\"],\n",
        "    n_layers=BASE_CONFIG[\"n_layers\"],\n",
        "    qkv_bias=BASE_CONFIG[\"qkv_bias\"],\n",
        "    vocab_size=BASE_CONFIG[\"vocab_size\"]\n",
        ")\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMMgQn3H4VgW"
      },
      "source": [
        "Let's assess the model's existing capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lAbp6Ew4VgW",
        "outputId": "e648d3dc-a418-4a4f-8048-bdbf2a4db674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBbx-WU74VgW",
        "outputId": "57f9be40-a834-49c6-9e4e-3ac51b6caad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "from generate import text_to_token_ids, token_ids_to_text, generate\n",
        "\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256\n",
        ")\n",
        "\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A02Pn0TP4VgW",
        "outputId": "db2dd9c0-1d03-41ad-ffbe-937f605f1ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "response_text = generated_text[len(input_text):].strip()\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pycNjic4VgX"
      },
      "source": [
        "## 7.6 Fine-tuning the LLM on instruction data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DpFyvv_C4VgX"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch = input_batch.to(device)\n",
        "    target_batch = target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(\n",
        "                input_batch, target_batch, model, device\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "dDdV2w6D6Snp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from generate import generate_text_simple\n",
        "\n",
        "\n",
        "def train_model_simple(\n",
        "    model, train_loader: DataLoader, val_loader: DataLoader,\n",
        "    optimizer, device, num_epochs: int, eval_freq: int, eval_iter: int,\n",
        "    start_context: str, tokenizer,\n",
        "):\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()  # reset loss gradients from previous iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()  # calculate loss gradients\n",
        "            optimizer.step()  # update model weights using the loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter\n",
        "                )\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(\n",
        "                    f\"Ep {epoch + 1} (Step {global_step:06d}): \"\n",
        "                    f\"Train loss {train_loss:.3f}, \"\n",
        "                    f\"Val loss {val_loss:.3f}\"\n",
        "                )\n",
        "\n",
        "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(\n",
        "    model, train_loader: DataLoader, val_loader: DataLoader, device, eval_iter: int\n",
        "):\n",
        "    model.eval()  # to disable dropout during evaluation\n",
        "    with torch.no_grad():  # to disable gradient tracking, it's not required (reduce computational overhead)\n",
        "        train_loss = calc_loss_loader(\n",
        "            train_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "M8IQ7JAY6mHk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fozb_wvo4VgX",
        "outputId": "b9f948fd-8218-471b-c3a5-fedb83a0cea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.825909471511841\n",
            "Validation loss: 3.761934232711792\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss}\")\n",
        "print(f\"Validation loss: {val_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC95BrZQ4VgX",
        "outputId": "0649f206-4563-44d6-c38f-fc6ad788d69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
            "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
            "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.533, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.568, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.604, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
            "Ep 1 (Step 000090): Train loss 0.563, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.504, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.565, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
            "Ep 1 (Step 000115): Train loss 0.509, Val loss 0.663\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.671\n",
            "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.686\n",
            "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
            "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
            "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.681\n",
            "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.681\n",
            "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
            "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.675\n",
            "Ep 2 (Step 000160): Train loss 0.412, Val loss 0.684\n",
            "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
            "Ep 2 (Step 000170): Train loss 0.322, Val loss 0.680\n",
            "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.668\n",
            "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
            "Ep 2 (Step 000185): Train loss 0.414, Val loss 0.657\n",
            "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
            "Ep 2 (Step 000195): Train loss 0.328, Val loss 0.634\n",
            "Ep 2 (Step 000200): Train loss 0.309, Val loss 0.634\n",
            "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.631\n",
            "Ep 2 (Step 000210): Train loss 0.362, Val loss 0.631\n",
            "Ep 2 (Step 000215): Train loss 0.393, Val loss 0.634\n",
            "Ep 2 (Step 000220): Train loss 0.297, Val loss 0.644\n",
            "Ep 2 (Step 000225): Train loss 0.341, Val loss 0.658\n",
            "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.656\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
            "Training completed in 3.12 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "exec_time_m = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {exec_time_m:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    ax2 = ax1.twiny()  # creates a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ka3pS70U8C7p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "g_G65Vj44VgX",
        "outputId": "b097d7e6-621f-4a33-d6fd-47ae5802ff06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiLdClqi4VgX"
      },
      "source": [
        "## 7.7 Extracting and saving responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54E7adHQ4VgY",
        "outputId": "2052ff86-0aea-488f-ef88-06b1085d3833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "--------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "--------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "    input_text = format_input(entry)\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG['context_length'],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "    )\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-\"*20)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}